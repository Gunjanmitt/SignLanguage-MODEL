{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb34a15-cfa9-4d84-ba3b-2b0dd77b7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import threading\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import time\n",
    "\n",
    "# Load model\n",
    "json_file = open(r'C:\\Users\\mehak\\signlanguagedetectionmodel48x48.json', \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(r'C:\\Users\\mehak\\signlanguagedetectionmodel48x48.h5')\n",
    "\n",
    "labels = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + ['blank']\n",
    "\n",
    "def extract_features(image):\n",
    "    feature = np.array(image).reshape(1, 48, 48, 1)\n",
    "    return feature / 255.0\n",
    "\n",
    "def speak_text(text):\n",
    "    if text.strip():\n",
    "        threading.Thread(target=_speak, args=(text,), daemon=True).start()\n",
    "\n",
    "def _speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def vertical_gradient(height, width, top_color, bottom_color):\n",
    "    gradient = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for y in range(height):\n",
    "        alpha = y / height\n",
    "        color = (np.array(top_color) * (1 - alpha) + np.array(bottom_color) * alpha).astype(np.uint8)\n",
    "        gradient[y, :] = color\n",
    "    return gradient\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "sentence = ''\n",
    "last_label = ''\n",
    "frame_count = 0\n",
    "cooldown = 10\n",
    "repeat_cooldown = 15\n",
    "repeat_counter = repeat_cooldown\n",
    "building_sentence = False\n",
    "pred_label = ''\n",
    "confidence = 0\n",
    "prev_sentences = []\n",
    "\n",
    "frame_width = 1280\n",
    "frame_height = 720\n",
    "cam_width = 720\n",
    "cam_height = 540\n",
    "\n",
    "x_offset = 50\n",
    "y_offset = 50\n",
    "\n",
    "cursor_on = True\n",
    "last_cursor_toggle = time.time()\n",
    "cursor_interval = 0.5\n",
    "\n",
    "cv2.namedWindow(\"Sign Language Recognition\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"Sign Language Recognition\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (cam_width, cam_height))\n",
    "    full_frame = vertical_gradient(frame_height, frame_width, (240, 240, 255), (180, 210, 255))\n",
    "\n",
    "    full_frame[y_offset:y_offset + cam_height, x_offset:x_offset + cam_width] = frame\n",
    "\n",
    "    # ROI rectangle - a bit larger: 250x250\n",
    "    roi_size = 250\n",
    "    roi_x1, roi_y1 = x_offset + 10, y_offset + 30\n",
    "    roi_x2, roi_y2 = roi_x1 + roi_size, roi_y1 + roi_size\n",
    "    cv2.rectangle(full_frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (0, 120, 255), 3)\n",
    "\n",
    "    # Extract ROI from frame for processing\n",
    "    roi = frame[roi_y1 - y_offset:roi_y2 - y_offset, roi_x1 - x_offset:roi_x2 - x_offset]\n",
    "\n",
    "    # Skin color segmentation to detect hand\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv_roi, lower_skin, upper_skin)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "    mask = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    "\n",
    "    # Find contours on the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw green dots on contour points if contours found\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        for point in largest_contour:\n",
    "            x, y = point[0]\n",
    "            if 0 <= x < roi.shape[1] and 0 <= y < roi.shape[0]:\n",
    "                cv2.circle(roi, (x, y), 3, (0, 255, 0), -1)  # green dot\n",
    "\n",
    "    # Prepare grayscale and resize for prediction\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (48, 48))\n",
    "    input_img = extract_features(resized)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % cooldown == 0:\n",
    "        pred = model.predict(input_img)\n",
    "        pred_label = labels[np.argmax(pred)]\n",
    "        confidence = np.max(pred)\n",
    "\n",
    "        if building_sentence:\n",
    "            if pred_label == 'blank':\n",
    "                last_label = ''\n",
    "                repeat_counter = repeat_cooldown\n",
    "            elif pred_label == last_label:\n",
    "                repeat_counter += 1\n",
    "                if repeat_counter >= repeat_cooldown:\n",
    "                    sentence += pred_label\n",
    "                    speak_text(pred_label)\n",
    "                    repeat_counter = 0\n",
    "            else:\n",
    "                sentence += pred_label\n",
    "                speak_text(pred_label)\n",
    "                last_label = pred_label\n",
    "                repeat_counter = 0\n",
    "\n",
    "    # Heading\n",
    "    text_pos = (frame_width // 2 - 110, 45)\n",
    "    cv2.putText(full_frame, \"ASL Model\", (text_pos[0] + 2, text_pos[1] + 2), cv2.FONT_HERSHEY_SIMPLEX, 1.4, (50, 50, 50), 5)\n",
    "    cv2.putText(full_frame, \"ASL Model\", text_pos, cv2.FONT_HERSHEY_SIMPLEX, 1.4, (110, 0, 190), 5)\n",
    "\n",
    "    # Prediction label\n",
    "    label_bg_top_left = (roi_x1, roi_y1 - 45)\n",
    "    label_bg_bottom_right = (roi_x1 + 220, roi_y1 - 5)\n",
    "    cv2.rectangle(full_frame, label_bg_top_left, label_bg_bottom_right, (0, 120, 255), -1)\n",
    "    label_text = f\"{pred_label}   {confidence * 100:.2f}%\"\n",
    "    cv2.putText(full_frame, label_text, (roi_x1 + 10, roi_y1 - 15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "    # Sentence Box\n",
    "    sent_box_tl = (50, 580)\n",
    "    sent_box_br = (880, 640)\n",
    "    cv2.rectangle(full_frame, sent_box_tl, sent_box_br, (245, 245, 245), -1)\n",
    "    cv2.rectangle(full_frame, sent_box_tl, sent_box_br, (0, 150, 50), 3)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_cursor_toggle > cursor_interval:\n",
    "        cursor_on = not cursor_on\n",
    "        last_cursor_toggle = current_time\n",
    "\n",
    "    display_sentence = sentence\n",
    "    if building_sentence and cursor_on:\n",
    "        display_sentence += '|'\n",
    "\n",
    "    cv2.putText(full_frame, \"Sentence:\", (sent_box_tl[0] + 15, sent_box_tl[1] + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 120, 0), 2)\n",
    "    cv2.putText(full_frame, display_sentence, (sent_box_tl[0] + 150, sent_box_tl[1] + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 90, 0), 2)\n",
    "\n",
    "    # Previous Sentences on Right\n",
    "    rect_top_left = (910, 50)\n",
    "    rect_bottom_right = (frame_width - 30, frame_height - 60)\n",
    "    cv2.rectangle(full_frame, rect_top_left, rect_bottom_right, (230, 230, 230), -1)\n",
    "    cv2.rectangle(full_frame, rect_top_left, rect_bottom_right, (100, 100, 100), 2)\n",
    "\n",
    "    cv2.putText(full_frame, \"Previous Sentences:\", (rect_top_left[0] + 15, rect_top_left[1] + 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 50, 130), 2)\n",
    "\n",
    "    for i, prev_sent in enumerate(prev_sentences[-18:][::-1]):\n",
    "        y_pos = rect_top_left[1] + 60 + i * 25\n",
    "        if y_pos < rect_bottom_right[1] - 10:\n",
    "            cv2.putText(full_frame, f\"- {prev_sent}\", (rect_top_left[0] + 15, y_pos),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 50, 50), 1)\n",
    "\n",
    "    # Instructions Bar\n",
    "    instructions = \"Press  's'=Start/Stop  |  'b'=Space  |  'p'=Speak  |  'c'=Clear+Save  |  ESC=Exit\"\n",
    "    cv2.rectangle(full_frame, (0, frame_height - 40), (frame_width, frame_height), (100, 100, 100), -1)\n",
    "    cv2.putText(full_frame, instructions, (50, frame_height - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Sign Language Recognition\", full_frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        building_sentence = not building_sentence\n",
    "    elif key == ord('p'):\n",
    "        if sentence.strip():\n",
    "            speak_text(sentence)\n",
    "    elif key == ord('c'):\n",
    "        if sentence.strip():\n",
    "            prev_sentences.append(sentence)\n",
    "        sentence = ''\n",
    "        last_label = ''\n",
    "        repeat_counter = repeat_cooldown\n",
    "    elif key == ord('b'):\n",
    "        sentence += ' '\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
